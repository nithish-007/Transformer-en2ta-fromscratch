{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "559c8e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------\n",
    "# importing Libraries\n",
    "# ---------------------------------\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "476678f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------\n",
    "# Input Embeddings\n",
    "# ---------------------------------\n",
    "\n",
    "class InputEnbeddings(nn.Module):\n",
    "    def __init__(self, d_model:int, vocab_size:int) -> None:\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embeddings = nn.Embedding(vocab_size, d_model)\n",
    "\n",
    "    def forwad(self, x):\n",
    "        # (batch, seq_len) --> (batch, seq_len, d_model)\n",
    "        # Multiply by sqrt(d_model) to scale the embeddings according to the the paper\n",
    "        return self.embeddings(x) * math.sqrt(self.d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5eb0276f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 9, 8, 1, 6],\n",
       "         [2, 3, 3, 7, 6]]),\n",
       " Parameter containing:\n",
       " tensor([[-1.2780,  0.8751, -0.2351, -1.2761,  0.5549],\n",
       "         [ 0.1548,  0.1161,  0.9773,  1.2093, -0.3735],\n",
       "         [-0.2943, -2.1374, -0.1426, -0.6374,  0.8016],\n",
       "         [-2.4155,  0.0477, -2.1817,  0.6429, -0.0706],\n",
       "         [-0.1482,  0.0647, -0.0669, -0.3310, -0.7109],\n",
       "         [ 0.2538,  1.6435,  0.5717, -0.1346, -0.7974],\n",
       "         [ 0.8568, -0.6566,  1.0557, -1.2519,  0.2087],\n",
       "         [ 1.2182, -0.4036, -0.4436,  0.5534, -1.1589],\n",
       "         [-1.4049, -2.0428,  3.1682, -0.5440,  1.0847],\n",
       "         [-1.0299,  0.8130, -0.3291,  1.2895,  0.8362]], requires_grad=True),\n",
       " tensor([[[ 0.1548,  0.1161,  0.9773,  1.2093, -0.3735],\n",
       "          [-1.0299,  0.8130, -0.3291,  1.2895,  0.8362],\n",
       "          [-1.4049, -2.0428,  3.1682, -0.5440,  1.0847],\n",
       "          [ 0.1548,  0.1161,  0.9773,  1.2093, -0.3735],\n",
       "          [ 0.8568, -0.6566,  1.0557, -1.2519,  0.2087]],\n",
       " \n",
       "         [[-0.2943, -2.1374, -0.1426, -0.6374,  0.8016],\n",
       "          [-2.4155,  0.0477, -2.1817,  0.6429, -0.0706],\n",
       "          [-2.4155,  0.0477, -2.1817,  0.6429, -0.0706],\n",
       "          [ 1.2182, -0.4036, -0.4436,  0.5534, -1.1589],\n",
       "          [ 0.8568, -0.6566,  1.0557, -1.2519,  0.2087]]],\n",
       "        grad_fn=<EmbeddingBackward0>))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = nn.Embedding(10, 5); b = torch.randint(low=1, high=10, size=(2,5))\n",
    "b, a.weight, a(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5919dc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------\n",
    "# Positional Embeddings\n",
    "# ---------------------------------\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model:int, seq_len:int, dropout:float) -> None:\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.seq_len = seq_len\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Create a matrix of shape (seq_len, d_model)\n",
    "        pe = torch.zeros(seq_len, d_model)\n",
    "        # Create a vector of shape (seq_len, 1)\n",
    "        position = torch.arange(0, seq_len, dtype=torch.float).unsqueeze(1) # (seq_len, 1)\n",
    "        # Create a vector of shape (d_model)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)) #(d_model / 2)\n",
    "        # apply sine to even indices\n",
    "        pe[:, 0::2] = torch.sin(position * div_term) # sin(position / 10000**(2i / d_model))\n",
    "        # apply cosine to off indices \n",
    "        pe[:, 1::2] = torch.cos(position * div_term) # cos(position / 10000**(2i / d_model))\n",
    "        # Add a batch dimension to the positional encoding \n",
    "        pe = pe.unsqueeze(0) # (1, seq_len, d_model)\n",
    "        # Register the positional encoding as a buffer\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + (self.pe[:, :x.shape[1], :]).requires_grad(False) # (batch, seq_len, d_model)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c2bdec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1548,  0.1161,  0.9773,  1.2093, -0.3735],\n",
       "         [-1.0299,  0.8130, -0.3291,  1.2895,  0.8362],\n",
       "         [-1.4049, -2.0428,  3.1682, -0.5440,  1.0847],\n",
       "         [ 0.1548,  0.1161,  0.9773,  1.2093, -0.3735],\n",
       "         [ 0.8568, -0.6566,  1.0557, -1.2519,  0.2087]],\n",
       "\n",
       "        [[-0.2943, -2.1374, -0.1426, -0.6374,  0.8016],\n",
       "         [-2.4155,  0.0477, -2.1817,  0.6429, -0.0706],\n",
       "         [-2.4155,  0.0477, -2.1817,  0.6429, -0.0706],\n",
       "         [ 1.2182, -0.4036, -0.4436,  0.5534, -1.1589],\n",
       "         [ 0.8568, -0.6566,  1.0557, -1.2519,  0.2087]]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "99fb7c6c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'bool' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m c = PositionalEncoding(\u001b[32m512\u001b[39m, \u001b[32m512\u001b[39m, \u001b[32m0.2\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nithish.kumar\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nithish.kumar\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mPositionalEncoding.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m     x = x + \u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpe\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequires_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# (batch, seq_len, d_model)\u001b[39;00m\n\u001b[32m     29\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dropout(x)\n",
      "\u001b[31mTypeError\u001b[39m: 'bool' object is not callable"
     ]
    }
   ],
   "source": [
    "c = PositionalEncoding(512, 512, 0.2)\n",
    "\n",
    "c(a(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ada95db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------\n",
    "# MultiHead Attention\n",
    "# ---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13eb51de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------\n",
    "# Encoder Block\n",
    "# ---------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1800877f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------\n",
    "# Residual Connection\n",
    "# ---------------------------------\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8422aecd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
