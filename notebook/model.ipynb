{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "559c8e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------\n",
    "# importing Libraries\n",
    "# ---------------------------------\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "476678f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------\n",
    "# Input Embeddings\n",
    "# ---------------------------------\n",
    "\n",
    "class InputEnbeddings(nn.Module):\n",
    "    def __init__(self, d_model:int, vocab_size:int) -> None:\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embeddings = nn.Embedding(vocab_size, d_model)\n",
    "\n",
    "    def forwad(self, x):\n",
    "        # (batch, seq_len) --> (batch, seq_len, d_model)\n",
    "        # Multiply by sqrt(d_model) to scale the embeddings according to the the paper\n",
    "        return self.embeddings(x) * math.sqrt(self.d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5eb0276f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 9, 8, 1, 6],\n",
       "         [2, 3, 3, 7, 6]]),\n",
       " Parameter containing:\n",
       " tensor([[-1.2780,  0.8751, -0.2351, -1.2761,  0.5549],\n",
       "         [ 0.1548,  0.1161,  0.9773,  1.2093, -0.3735],\n",
       "         [-0.2943, -2.1374, -0.1426, -0.6374,  0.8016],\n",
       "         [-2.4155,  0.0477, -2.1817,  0.6429, -0.0706],\n",
       "         [-0.1482,  0.0647, -0.0669, -0.3310, -0.7109],\n",
       "         [ 0.2538,  1.6435,  0.5717, -0.1346, -0.7974],\n",
       "         [ 0.8568, -0.6566,  1.0557, -1.2519,  0.2087],\n",
       "         [ 1.2182, -0.4036, -0.4436,  0.5534, -1.1589],\n",
       "         [-1.4049, -2.0428,  3.1682, -0.5440,  1.0847],\n",
       "         [-1.0299,  0.8130, -0.3291,  1.2895,  0.8362]], requires_grad=True),\n",
       " tensor([[[ 0.1548,  0.1161,  0.9773,  1.2093, -0.3735],\n",
       "          [-1.0299,  0.8130, -0.3291,  1.2895,  0.8362],\n",
       "          [-1.4049, -2.0428,  3.1682, -0.5440,  1.0847],\n",
       "          [ 0.1548,  0.1161,  0.9773,  1.2093, -0.3735],\n",
       "          [ 0.8568, -0.6566,  1.0557, -1.2519,  0.2087]],\n",
       " \n",
       "         [[-0.2943, -2.1374, -0.1426, -0.6374,  0.8016],\n",
       "          [-2.4155,  0.0477, -2.1817,  0.6429, -0.0706],\n",
       "          [-2.4155,  0.0477, -2.1817,  0.6429, -0.0706],\n",
       "          [ 1.2182, -0.4036, -0.4436,  0.5534, -1.1589],\n",
       "          [ 0.8568, -0.6566,  1.0557, -1.2519,  0.2087]]],\n",
       "        grad_fn=<EmbeddingBackward0>))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = nn.Embedding(10, 5); b = torch.randint(low=1, high=10, size=(2,5))\n",
    "b, a.weight, a(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5919dc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------\n",
    "# Positional Embeddings\n",
    "# ---------------------------------\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model:int, seq_len:int, dropout:float) -> None:\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.seq_len = seq_len\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Create a matrix of shape (seq_len, d_model)\n",
    "        pe = torch.zeros(seq_len, d_model)\n",
    "        # Create a vector of shape (seq_len, 1)\n",
    "        position = torch.arange(0, seq_len, dtype=torch.float).unsqueeze(1) # (seq_len, 1)\n",
    "        # Create a vector of shape (d_model)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)) #(d_model / 2)\n",
    "        # apply sine to even indices\n",
    "        pe[:, 0::2] = torch.sin(position * div_term) # sin(position / 10000**(2i / d_model))\n",
    "        # apply cosine to off indices \n",
    "        pe[:, 1::2] = torch.cos(position * div_term) # cos(position / 10000**(2i / d_model))\n",
    "        # Add a batch dimension to the positional encoding \n",
    "        pe = pe.unsqueeze(0) # (1, seq_len, d_model)\n",
    "        # Register the positional encoding as a buffer\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + (self.pe[:, :x.shape[1], :]).requires_grad(False) # (batch, seq_len, d_model)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c2bdec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1548,  0.1161,  0.9773,  1.2093, -0.3735],\n",
       "         [-1.0299,  0.8130, -0.3291,  1.2895,  0.8362],\n",
       "         [-1.4049, -2.0428,  3.1682, -0.5440,  1.0847],\n",
       "         [ 0.1548,  0.1161,  0.9773,  1.2093, -0.3735],\n",
       "         [ 0.8568, -0.6566,  1.0557, -1.2519,  0.2087]],\n",
       "\n",
       "        [[-0.2943, -2.1374, -0.1426, -0.6374,  0.8016],\n",
       "         [-2.4155,  0.0477, -2.1817,  0.6429, -0.0706],\n",
       "         [-2.4155,  0.0477, -2.1817,  0.6429, -0.0706],\n",
       "         [ 1.2182, -0.4036, -0.4436,  0.5534, -1.1589],\n",
       "         [ 0.8568, -0.6566,  1.0557, -1.2519,  0.2087]]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fb7c6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ada95db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------\n",
    "# MultiHead Attention\n",
    "# ---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13eb51de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------\n",
    "# Encoder Block\n",
    "# ---------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1800877f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------\n",
    "# Residual Connection\n",
    "# ---------------------------------\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8422aecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[2, 7, 1],\n",
       "         [6, 3, 5],\n",
       "         [1, 9, 3]]),\n",
       " tensor([[2],\n",
       "         [9],\n",
       "         [6]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "a = torch.randint(low=1, high=10, size=(3,3)); b = torch.randint(low=1, high=10, size=(3,1))\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "575c0cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 73],\n",
       "        [ 69],\n",
       "        [101]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a@b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee90cde8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
